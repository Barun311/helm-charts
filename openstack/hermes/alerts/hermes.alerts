groups:
- name: openstack-hermes.alerts
  rules:
  - alert: OpenstackHermesKeystoneAvail
    expr: sum(rate(hermes_logon_errors_count[10m])) > 0
    for: 15m
    labels:
      context: availability
      dashboard: hermes-details
      service: hermes
      severity: warning
      tier: os
      support_group: observability
    annotations:
      description: Hermes API is affected by errors when accessing Keystone
      summary: Hermes availability affected by Keystone issues

  - alert: OpenstackHermesElasticAvail
    expr: sum(rate(hermes_storage_errors_count[10m])) > 0
    for: 15m
    labels:
      context: availability
      dashboard: hermes-details
      service: hermes
      severity: warning
      tier: os
      support_group: observability
    annotations:
      description: Hermes API is affected by storage errors while accessing Elasticsearch
      summary: Hermes availability affected by storage errors while accessing Elasticsearch

  - alert: OpenstackHermesRabbitMQUnack
    expr: sum(rabbitmq_queue_messages_unacknowledged{kubernetes_name=~".*rabbitmq-notifications"}) by (kubernetes_name) > 6000
    labels:
      context: rabbitmq
      severity: warning
      tier: os
      support_group: observability
      service: hermes
      dashboard: rabbitmq
      meta: '{{ $labels.service }} {{ $labels.check }} has over 6000 unacknowledged messages in {{ $labels.kubernetes_name }}. Logstash has disconnected from the RabbitMQ.'
      playbook: 'docs/devops/alert/hermes/#{{ $labels.check }}'
    annotations:
      description: '{{ $labels.service }} {{ $labels.check }} has over 6000 unacknowledged messages in {{ $labels.kubernetes_name }}. Logstash has disconnected from the RabbitMQ.'
      summary: 'RabbitMQ unacknowledged messages count'

  - alert: OpenstackHermesRabbitMQReady
    expr: sum(rabbitmq_queue_messages_ready{kubernetes_name=~".*rabbitmq-notifications"}) by (kubernetes_name) > 4000
    labels:
      context: rabbitmq
      severity: warning
      tier: os
      support_group: observability
      service: hermes
      dashboard: rabbitmq
      meta: '{{ $labels.service }} {{ $labels.check }} has over 4000 ready messages in {{ $labels.kubernetes_name }}. Logstash has disconnected from the RabbitMQ.'
      playbook: 'docs/devops/alert/rabbitmq/#ready'
    annotations:
      description: '{{ $labels.service }} {{ $labels.check }} has over 4000 unacknowledged messages in {{ $labels.kubernetes_name }}. Logstash has disconnected from the RabbitMQ.'
      summary: 'RabbitMQ unacknowledged messages count'

  - alert: OpenstackHermesLogstashPlugins
    expr: sum(increase(logstash_node_plugin_events_out_total[30m])) <= 0
    labels:
      context: logstash
      severity: warning
      tier: os
      support_group: observability
      service: hermes
      dashboard: hermes-logstash-metrics
      meta: 'Hermes logstash plugin {{ $labels.plugin }} has stopped transmitting data'
      playbook: 'docs/devops/alert/hermes'
    annotations:
      description: 'Hermes logstash plugin {{ $labels.plugin }} has stopped transmitting data'
      summary: 'Hermes logstash plugin {{ $labels.plugin }} has stopped transmitting data'

  - alert: OpenstackHermesLogstashPluginsJDBCStaticFailure
    expr: sum(rate(logstash_node_plugin_failures_total{namespace=~"hermes",plugin="jdbc_static"}[10m])) > 0
    labels:
      context: logstash
      severity: warning
      tier: os
      support_group: observability
      service: hermes
      dashboard: hermes-logstash-metrics
      meta: 'Hermes logstash plugin {{ $labels.plugin }} has failed enriching data with Metis'
      playbook: 'docs/devops/alert/hermes'
    annotations:
      description: 'Hermes logstash plugin {{ $labels.plugin }} has failed enriching data with Metis'
      summary: 'Hermes logstash plugin {{ $labels.plugin }} has failed enriching data with Metis'
      
  - alert: OpenstackHermesPodSchedulingFailedInsufficientCPU
    expr: sum(rate(kube_pod_failed_scheduling_cpu_total{pod_name=~"hermes-.+"}[30m])) by (pod_name) > 0
    for: 15m
    labels:
      context: cpu
      severity: warning
      support_group: observability
      tier: os
      service: hermes
      dashboard: hermes-details
      meta: "{{ $labels.pod_name }}"
      no_alert_on_absence: "true" # the underlying metric is only generated when scheduling fails
    annotations:
      summary: Scheduling failed due to insufficient cpu
      description: The pod {{ $labels.pod_name }} failed to be scheduled. Insuffient CPU!
