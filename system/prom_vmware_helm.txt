---
# Source: prometheus-vmware/charts/prometheus-server/templates/service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus-vmware
  labels:
    prometheus: vmware
---
# Source: prometheus-vmware/charts/prometheus-server/templates/alertmanager-config.yaml
apiVersion: v1
kind: Secret

metadata:
  name: prometheus-vmware-alertmanager-config
  labels:
    prometheus: vmware

data:
  config.yaml: LSBzY2hlbWU6IGh0dHBzCiAgdGltZW91dDogMTBzCiAgCgogIHN0YXRpY19jb25maWdzOgogICAgLSB0YXJnZXRzOgogICAgICAgIC0gYWxlcnRtYW5hZ2VyLWludGVybmFsLnNjYWxlb3V0LmV1LWRlLTEuY2xvdWQuc2FwCiAgICAgICAgLSBhbGVydG1hbmFnZXItaW50ZXJuYWwuc2NhbGVvdXQuZXUtbmwtMS5jbG91ZC5zYXAK
  relabelConfig.yaml: LSBhY3Rpb246IHJlcGxhY2UKICB0YXJnZXRfbGFiZWw6IHJlZ2lvbgogIHJlcGxhY2VtZW50OiBxYS1kZS0xCgotIGFjdGlvbjogcmVwbGFjZQogIHRhcmdldF9sYWJlbDogY2x1c3Rlcl90eXBlCiAgcmVwbGFjZW1lbnQ6IGNvbnRyb2xwbGFuZQoKLSBhY3Rpb246IHJlcGxhY2UKICB0YXJnZXRfbGFiZWw6IGNsdXN0ZXIKICByZXBsYWNlbWVudDogcWEtZGUtMQo=
---
# Source: prometheus-vmware/charts/prometheus-server/templates/cluster-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole

metadata:
  name: prometheus-vmware
  labels:
    prometheus: vmware

rules:
  - apiGroups:
      - ""
    resources:
      - nodes
      - nodes/metrics
      - nodes/metrics/cadvisor
      - services
      - endpoints
      - pods
    verbs:
      - get
      - list
      - watch

  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get

  - apiGroups:
      - extensions
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch

  - nonResourceURLs:
      - "/metrics"
      - "/metrics/cadvisor"
      - "/metrics/resource"
      - "/metrics/probes"
    verbs:
      - get
---
# Source: prometheus-vmware/charts/prometheus-server/templates/cluster-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding

metadata:
  name: prometheus-vmware
  labels:
    prometheus: vmware

roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus-vmware

subjects:
  - kind: ServiceAccount
    name: prometheus-vmware
    namespace: default
---
# Source: prometheus-vmware/charts/prometheus-server/templates/service.yaml
apiVersion: v1
kind: Service

metadata:
  name: prometheus-vmware
  labels:
    prometheus: vmware
  

spec:
  selector:
    app: prometheus
    prometheus: vmware
  ports:
    - name: http
      port: 9090
---
# Source: prometheus-vmware/charts/prometheus-server/templates/ingress-internal.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress

metadata:
  name: prometheus-vmware-internal
  labels:
    prometheus: vmware
  annotations:
    kubernetes.io/tls-acme: "true"
    disco: "true"
    ingress.kubernetes.io/auth-tls-secret: "kube-system/ingress-cacrt"
    ingress.kubernetes.io/auth-tls-verify-depth: "3"
    ingress.kubernetes.io/auth-tls-verify-client: "true"
    

spec:
  rules:
    - host: prometheus-vmware-internal.qa-de-1.cloud.sap
      http:
        paths:
          - path: /api
            backend:
              serviceName: prometheus-vmware
              servicePort: http
          - path: /federate
            backend:
              serviceName: prometheus-vmware
              servicePort: http
  tls:
    - secretName: tls-internal-prometheus-vmware-qa-de-1-cloud-sap
      hosts:
        - prometheus-vmware-internal.qa-de-1.cloud.sap
---
# Source: prometheus-vmware/charts/prometheus-server/templates/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress

metadata:
  name: prometheus-vmware
  labels:
    prometheus: vmware
  annotations:
    kubernetes.io/tls-acme: "true"
    disco: "true"
    ingress.kubernetes.io/auth-tls-secret: "kube-system/ingress-cacrt"
    ingress.kubernetes.io/auth-tls-verify-depth: "3"
    ingress.kubernetes.io/auth-tls-verify-client: "true"
    

spec:
  rules:
    - host: prometheus-vmware.qa-de-1.cloud.sap
      http:
        paths:
        - path: /
          backend:
            serviceName: prometheus-vmware
            servicePort: http
  tls:
    - secretName: tls-prometheus-vmware-qa-de-1-cloud-sap
      hosts:
        - prometheus-vmware.qa-de-1.cloud.sap
---
# Source: prometheus-vmware/charts/prometheus-server/templates/podmonitors/pod-sd.yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor

metadata:
  name: prometheus-vmware-pod-sd
  labels:
    prometheus: vmware

spec:
  jobLabel: pod-sd

  # Selector not used but required in k8s 1.10+ .
  selector:
    matchExpressions:
      - key: foo
        operator: DoesNotExist

  # Find pods in any namespace.
  namespaceSelector:
    any: true

  podMetricsEndpoints:
    - interval: 30s
      scrapeTimeout: 25s
      scheme: http
      honorLabels: true
      relabelings:
        - action: keep
          sourceLabels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scrape
          regex: 'true'
        - action: keep
          sourceLabels:
            - __meta_kubernetes_pod_annotation_prometheus_io_targets
          regex: ".*vmware.*"
        - action: keep
          sourceLabels:
            - __meta_kubernetes_pod_container_port_number
            - __meta_kubernetes_pod_container_port_name
            - __meta_kubernetes_pod_annotation_prometheus_io_port
          regex: '(9102;.*;.*)|(.*;metrics;.*)|(\d+;.*;\d+)|(.*;.*;\d+)'
        - sourceLabels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scheme
          targetLabel: __scheme__
          regex: '(https?)'
        - sourceLabels:
            - __meta_kubernetes_pod_annotation_prometheus_io_path
          targetLabel: __metrics_path__
          regex: '(.+)'
        - sourceLabels:
            - __address__
            - __meta_kubernetes_pod_annotation_prometheus_io_port
          targetLabel: __address__
          regex: '([^:]+)(?::\d+)?;(\d+)'
          replacement: ${1}:${2}
        - action: labelmap
          regex: '__meta_kubernetes_pod_label_(.+)'
        - sourceLabels:
            - __meta_kubernetes_namespace
          targetLabel: kubernetes_namespace
        - sourceLabels:
            - __meta_kubernetes_pod_name
          targetLabel: kubernetes_pod_name
        - action: replace
          targetLabel: region
          replacement: qa-de-1
        - action: replace
          targetLabel: cluster_type
          replacement: controlplane
        - action: replace
          targetLabel: cluster
          replacement: qa-de-1



    - interval: 30s
      scrapeTimeout: 25s
      scheme: http
      honorLabels: true
      relabelings:
        - action: keep
          sourceLabels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scrape
          regex: 'true'
        - action: keep
          sourceLabels:
            - __meta_kubernetes_pod_annotation_prometheus_io_targets
          regex: ".*vmware.*"
        - action: keep
          sourceLabels:
            - __meta_kubernetes_pod_annotation_prometheus_io_port_1
          regex: '\d+'
        - action: keep
          sourceLabels:
            - __meta_kubernetes_pod_container_port_number
            - __meta_kubernetes_pod_container_port_name
            - __meta_kubernetes_pod_annotation_prometheus_io_port_1
          regex: '(9102;.*;.*)|(.*;metrics;.*)|(\d+;.*;\d+)|(.*;.*;\d+)'
        - sourceLabels:
            - __meta_kubernetes_pod_annotation_prometheus_io_scheme
          targetLabel: __scheme__
          regex: '(https?)'
        - sourceLabels:
            - __meta_kubernetes_pod_annotation_prometheus_io_path
          targetLabel: __metrics_path__
          regex: '(.+)'
        - sourceLabels:
            - __address__
            - __meta_kubernetes_pod_annotation_prometheus_io_port_1
          targetLabel: __address__
          regex: '([^:]+)(?::\d+)?;(\d+)'
          replacement: ${1}:${2}
        - action: labelmap
          regex: '__meta_kubernetes_pod_label_(.+)'
        - sourceLabels:
            - __meta_kubernetes_namespace
          targetLabel: kubernetes_namespace
        - sourceLabels:
            - __meta_kubernetes_pod_name
          targetLabel: kubernetes_pod_name
        - action: replace
          targetLabel: region
          replacement: qa-de-1
        - action: replace
          targetLabel: cluster_type
          replacement: controlplane
        - action: replace
          targetLabel: cluster
          replacement: qa-de-1
---
# Source: prometheus-vmware/charts/prometheus-server/templates/prometheus-server.yaml
apiVersion: monitoring.coreos.com/v1
kind: Prometheus

metadata:
  name: vmware
  labels:
    prometheus: vmware

spec:
  replicas: 1

  serviceAccountName: prometheus-vmware

  image: keppel.eu-de-1.cloud.sap/ccloud-dockerhub-mirror/prom/prometheus:v2.34.0

  # Select all ServiceMonitors with the label 'prometheus: <name>'.
  serviceMonitorSelector:
    matchLabels:
      prometheus: vmware

  # Select all PodMonitors with the label 'prometheus: <name>'.
  podMonitorSelector:
    matchLabels:
      prometheus: vmware

  

  # Select all (aggregation, alerting) PrometheusRules with the label 'prometheus: <name>'.
  ruleSelector:
    matchLabels:
      prometheus: vmware

  # Select rules, serviceMonitors, podMonitors from all namespaces.
  ruleNamespaceSelector: {}
  serviceMonitorNamespaceSelector: {}
  podMonitorNamespaceSelector: {}

  # The labels to add to any time series or alerts when communicating with external systems (federation, remote storage, Alertmanager).
  # If Thanos is enabled the prefix `thanos_` is added to external labels to avoid overriding existing ones (region, cluster)
  # which might have been added by previous Prometheis in the federation hierarchy.
  externalLabels:
    region: qa-de-1
    cluster: qa-de-1
    cluster_type: controlplane

  

  
  # Interval between consecutive scrapes.
  scrapeInterval: 60s
  

  

  # Mount additional secrets from the same namespace.
  secrets: []
  

  # Alertmanager configuration.
  additionalAlertManagerConfigs:
    name: prometheus-vmware-alertmanager-config
    key: config.yaml

  # Alertmanager configuration to ensure mandatory labels are present on alerts.
  additionalAlertRelabelConfigs:
    name: prometheus-vmware-alertmanager-config
    key: relabelConfig.yaml

  # The external URL of the Prometheus.
  externalUrl: https://prometheus-vmware.qa-de-1.cloud.sap

  # The retention time of the Prometheus.
  retention: 8h

  # The log level of the Prometheus.
  logLevel: info

  # Storage configuration.
  # If configured, persistent storage is used, alternatively data is stored in memory.
  storage:
    volumeClaimTemplate:
      metadata:
        name: "vmware"
        labels:
          prometheus: vmware
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "100Gi"
        
    
  # Kubernetes resource requests and limits if configured.
  resources:
    requests:
      cpu: 500m
      memory: 4Gi
  

  
  # A security context defines privilege and access control settings for a Pod or Container.
  securityContext:
    fsGroup: 0
    runAsUser: 0
---
# Source: prometheus-vmware/charts/kube-state-metrics-exporter/templates/prometheus-aggregations.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule

metadata:
  name: kube-state-metrics-aggregations-aggregations.rules
  labels:
    app: kube-state-metrics
    prometheus: vmware

spec:
  groups:
    - name: kube-state-metrics-normalization.rules
      rules:
        - record: kube_node_info_normalized
          expr: max by(cluster, region, cluster_type, container_runtime_version, kernel_version, kubelet_version, kubeproxy_version, node, os_image) (kube_node_info)
  
        - record: kube_node_status_condition_normalized
          expr: max by(cluster, region, cluster_type, node, condition, status) (kube_node_status_condition)
  
        - record: kube_pod_info_normalized
          expr: max by (region, cluster, cluster_type, namespace, pod, node) (kube_pod_info)
  
          # Join the node name to the kube_pod_info metric.
        - record: kube_pod_status_ready_normalized
          expr: max by(region, cluster, cluster_type, namespace, pod, condition) (kube_pod_status_ready) * on(pod) group_left(node) max by (pod, node) (kube_pod_info)
  
        - record: kube_pod_status_phase_normalized
          expr: max by(region, cluster, cluster_type, namespace, pod, node, phase) (kube_pod_status_phase) * on(pod) group_left(node) max by (node, pod) (kube_pod_info)
  
        - record: kube_pod_container_resource_requests_memory_bytes_average
          expr: |
              avg(
                  count_over_time(kube_pod_container_resource_requests_memory_bytes{container!="",container!="POD", node!=""}[5m])
                  *
                  avg_over_time(kube_pod_container_resource_requests_memory_bytes{container!="",container!="POD", node!=""}[5m])
              ) by (namespace, container, pod, node, cluster)
  
        - record: kube_pod_container_resource_requests_cpu_cores_average
          expr: |
              avg(
                  count_over_time(kube_pod_container_resource_requests_cpu_cores{container!="",container!="POD", node!=""}[5m])
                  *
                  avg_over_time(kube_pod_container_resource_requests_cpu_cores{container!="",container!="POD", node!=""}[5m])
              ) by (namespace, container, pod, node, cluster)
  
        - record: kube_persistentvolumeclaim_resource_requests_storage_bytes_average
          expr: |
              avg(kube_persistentvolumeclaim_info) by (persistentvolumeclaim, storageclass, namespace, volumename, cluster)
              *
              on (persistentvolumeclaim, namespace, cluster) group_right(storageclass, volumename)
              sum(kube_persistentvolumeclaim_resource_requests_storage_bytes) by (persistentvolumeclaim, namespace, cluster)
---
# Source: prometheus-vmware/charts/prometheus-server/templates/alerts/prometheus-alerts.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule

metadata:
  name: prometheus-vmware-prometheus.alerts
  labels:
    prometheus: vmware

spec:
  groups:
  - name: prometheus.alerts
    rules:
    - alert: PrometheusFailedConfigReload
      expr: prometheus_config_last_reload_successful{prometheus="vmware"} == 0
      for: 5m
      labels:
        context: availability
        service: prometheus
        severity: critical
        tier: monitor
        playbook: 'docs/support/playbook/prometheus/failed_config_reload.html'
        meta: 'Prometheus {{ $labels.prometheus }} failed to load it`s configuration.'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} failed to load it`s configuration. Prometheus cannot start with a malformed configuration.'
        summary: Prometheus configuration reload has failed
  
    - alert: PrometheusRuleEvaluationFailed
      expr: increase(prometheus_rule_evaluation_failures_total{prometheus="vmware"}[5m]) > 0
      for: 15m
      labels:
        context: availability
        service: prometheus
        severity: warning
        tier: monitor
        playbook: 'docs/support/playbook/prometheus/rule_evaluation.html'
        meta: 'Prometheus {{ $labels.prometheus }} failed to evaluate rules.'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} failed to evaluate rules. Aggregation or alerting rules may not be loaded or provide false results.'
        summary: Prometheus rule evaluation failed
  
    - alert: PrometheusRuleEvaluationSlow
      expr: prometheus_rule_evaluation_duration_seconds{quantile="0.9", prometheus="vmware"} > 60
      for: 10m
      labels:
        context: availability
        service: prometheus
        severity: info
        tier: monitor
        playbook: 'docs/support/playbook/prometheus/rule_evaluation.html'
        meta: 'Prometheus {{ $labels.prometheus }} rule evaluation is slow.'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} rule evaluation is slow'
        summary: Prometheus rule evaluation is slow
  
    - alert: PrometheusWALCorruption
      expr: increase(prometheus_tsdb_wal_corruptions_total{prometheus="vmware"}[5m]) > 0
      labels:
        context: availability
        service: prometheus
        severity: info
        tier: monitor
        playbook: 'docs/support/playbook/prometheus/wal.html'
        meta: 'Prometheus {{ $labels.prometheus }} has {{ $value }} WAL corruptions.'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }}  has {{ $value }} WAL corruptions.'
        summary: Prometheus has WAL corruptions
  
    - alert: PrometheusTSDBReloadsFailing
      expr: increase(prometheus_tsdb_reloads_failures_total{prometheus="vmware"}[2h]) > 0
      for: 12h
      labels:
        context: availability
        service: prometheus
        severity: info
        tier: monitor
        playbook: 'docs/support/playbook/prometheus/failed_tsdb_reload.html'
        meta: 'Prometheus {{ $labels.prometheus }} failed to reload TSDB.'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} had {{$value | humanize}} reload failures over the last four hours.'
        summary: Prometheus has issues reloading data blocks from disk
  
    - alert: PrometheusNotIngestingSamples
      expr: rate(prometheus_tsdb_head_samples_appended_total{prometheus="vmware"}[5m]) <= 0 or absent(prometheus_tsdb_head_samples_appended_total{prometheus="vmware"}) or absent(scrape_samples_scraped{prometheus="vmware"})
      for: 10m
      labels:
        context: availability
        service: prometheus
        severity: info
        tier: monitor
        playbook: 'docs/support/playbook/prometheus/failed_scrapes.html'
        meta: 'Prometheus {{ $labels.prometheus }} not ingesting samples.'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} not ingesting samples. Aggregation or alerting rules may not be loaded or provide false results.'
        summary: Prometheus not ingesting samples.
  
    - alert: PrometheusTargetScrapesDuplicate
      expr: increase(prometheus_target_scrapes_sample_duplicate_timestamp_total{prometheus="vmware"}[5m]) > 0
      for: 10m
      labels:
        context: availability
        service: prometheus
        severity: info
        tier: monitor
        playbook: 'docs/support/playbook/prometheus/failed_scrapes.html'
        meta: 'Prometheus {{ $labels.prometheus }} rejects many samples'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} has many samples rejected due to duplicate timestamps but different values. This indicates metric duplication.'
        summary: Prometheus rejects many samples
  
    - alert: PrometheusOutOfOrderTimestamps
      expr: rate(prometheus_target_scrapes_sample_out_of_order_total{prometheus="vmware"}[5m]) > 0
      labels:
        context: availability
        service: prometheus
        severity: info
        tier: monitor
        playbook: 'docs/support/playbook/prometheus/failed_scrapes.html'
        meta: 'Prometheus {{ $labels.prometheus }} drops samples with out-of-order timestamps.'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} has many samples rejected due to out-of-order timestamps.'
        summary: Prometheus drops samples with out-of-order timestamps
  
    - alert: PrometheusLargeScrapes
      expr: increase(prometheus_target_scrapes_exceeded_sample_limit_total{prometheus="vmware"}[30m]) > 60
      labels:
        context: availability
        service: prometheus
        severity: info
        tier: monitor
        playbook: 'docs/support/playbook/prometheus/failed_scrapes.html'
        meta: 'Prometheus {{ $labels.prometheus }} fails to scrape targets'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} has many scrapes that exceed the sample limit'
        summary: Prometheus fails to scrape targets.
  
    - alert: PrometheusMultipleTargetScrapes
      # we exclude cadvisor metrics because it has the same instance as the kubelet but a different path
      # e.g. 10.246.204.80:10250/metrics vs. 10.246.204.80:10250/metrics/cadvisor
      expr: sum by (job) (up * on(instance) group_left() (sum by(instance) (up{component!="cadvisor"}) > 1))
      for: 30m
      labels:
        tier: monitor
        service: prometheus
        severity: warning
        playbook: docs/support/playbook/kubernetes/target_scraped_multiple_times.html
        meta: 'Prometheus is scraping targets of job {{ $labels.job }} more than once.'
      annotations:
        description: Prometheus is scraping individual targets of the job `{{ $labels.job }}` more than once. This is likely caused due to incorrectly placed scrape annotations.  <https://prometheus-vmware.qa-de-1.cloud.sap/graph?g0.expr=up+%2A+on%28instance%29+group_left%28%29+%28sum+by%28instance%29+%28up%7Bjob%3D%22{{ $labels.job }}%22%7D%29+%3E+1%29|Affected targets>
        summary: Prometheus target scraped multiple times
    - alert: PrometheusNotConnectedToAlertmanagers
      expr: prometheus_notifications_alertmanagers_discovered{prometheus="vmware"} == 0
      for: 10m
      labels:
        context: availability
        service: prometheus
        severity: warning
        tier: monitor
        meta: 'Prometheus {{ $labels.prometheus }} lost connection to all Alertmanagers'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} lost connection to all configured Alertmanagers. Alerting is unavailable.'
        summary: Prometheus not connected to any Alertmanager
  
    - alert: PrometheusErrorSendingAlerts
      expr: rate(prometheus_notifications_errors_total{prometheus="vmware"}[5m]) / rate(prometheus_notifications_sent_total{prometheus="vmware"}[5m]) > 0.01
      for: 10m
      labels:
        context: availability
        service: prometheus
        severity: info
        tier: monitor
        meta: 'Prometheus {{ $labels.prometheus }} fails to send alerts'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} is having errors sending alerts to Alertmanager {{ $labels.alertmanager }}'
        summary: Prometheus fails to send alerts
  
    - alert: PrometheusNotificationsBacklog
      expr: prometheus_notifications_queue_length{prometheus="vmware"} > 0
      for: 10m
      labels:
        context: availability
        service: prometheus
        severity: info
        tier: monitor
        meta: 'Prometheus {{ $labels.prometheus }} queueing notifications'
      annotations:
        description: 'Prometheus {{ $labels.prometheus }} is backlogging on the notifications queue. The queue has not been empty for 10 minutes. Current queue length {{ $value }}.'
        summary: Prometheus is queueing notifications.
---
# Source: prometheus-vmware/charts/kube-state-metrics-exporter/templates/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor

metadata:
  name: prometheus-vmware-kube-state-metrics
  labels:
    prometheus: "vmware"
    app: kube-state-metrics

spec:
  selector:
    matchLabels:
      
      app: kube-state-metrics

  namespaceSelector:
    any: true

  endpoints:
    - port: http
      honorLabels: true
      relabelings:
        - action: replace
          targetLabel: prometheus
          replacement: vmware
        - action: labelmap
          regex: '__meta_kubernetes_service_label_(.+)'
        - sourceLabels:
            - __meta_kubernetes_namespace
          targetLabel: kubernetes_namespace
        - sourceLabels:
            - __meta_kubernetes_service_name
          targetLabel: kubernetes_name
        - action: replace
          targetLabel: region
          replacement: qa-de-1
        - action: replace
          targetLabel: cluster_type
          replacement: controlplane
        - action: replace
          targetLabel: cluster
          replacement: qa-de-1
---
# Source: prometheus-vmware/charts/prometheus-server/templates/servicemonitors/endpoint-sd.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor

metadata:
  name: prometheus-vmware-endpoint-sd
  labels:
    prometheus: vmware

spec:
  jobLabel: endpoint-sd

  # Selector not used but required in k8s 1.10+ .
  selector:
    matchExpressions:
      - key: foo
        operator: DoesNotExist

  # Find endpoints in any namespace.
  namespaceSelector:
    any: true

  endpoints:
    - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
      interval: 30s
      scrapeTimeout: 25s
      scheme: http
      honorLabels: true
      relabelings:
        - action: keep
          sourceLabels:
            - __meta_kubernetes_service_annotation_prometheus_io_scrape
          regex: 'true'
        - action: keep
          sourceLabels:
            - __meta_kubernetes_service_annotation_prometheus_io_targets
          regex: ".*vmware.*"
        - action: keep
          sourceLabels:
            - __meta_kubernetes_endpoint_ready
          regex: '(.+)'
        - action: keep
          sourceLabels:
            - __meta_kubernetes_service_port_name
            - __meta_kubernetes_service_annotation_prometheus_io_port
          regex: '(metrics;.*)|(.*;\d+)'
        - sourceLabels:
            - __meta_kubernetes_service_annotation_prometheus_io_scheme
          targetLabel: __scheme__
          regex: '(https?)'
        - sourceLabels:
            - __meta_kubernetes_service_annotation_prometheus_io_path
          targetLabel: __metrics_path__
          regex: '(.+)'
        - sourceLabels:
            - __address__
            - __meta_kubernetes_service_annotation_prometheus_io_port
          targetLabel: __address__
          regex: '([^:]+)(?::\d+)?;(\d+)'
          replacement: $1:$2
        - action: labelmap
          regex: '__meta_kubernetes_service_label_(.+)'
        - sourceLabels:
            - __meta_kubernetes_namespace
          targetLabel: kubernetes_namespace
        - sourceLabels:
            - __meta_kubernetes_service_name
          targetLabel: kubernetes_name
        - action: labelmap
          replacement: __param_$1
          regex: '__meta_kubernetes_service_annotation_prometheus_io_scrape_param_(.+)'
        - action: replace
          targetLabel: region
          replacement: qa-de-1
        - action: replace
          targetLabel: cluster_type
          replacement: controlplane
        - action: replace
          targetLabel: cluster
          replacement: qa-de-1



    - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
      interval: 30s
      scrapeTimeout: 25s
      scheme: http
      honorLabels: true
      relabelings:
        - action: keep
          sourceLabels:
            - __meta_kubernetes_service_annotation_prometheus_io_scrape
          regex: 'true'
        - action: keep
          sourceLabels:
            - __meta_kubernetes_service_annotation_prometheus_io_targets
          regex: ".*vmware.*"
        - action: keep
          sourceLabels:
            - __meta_kubernetes_service_annotation_prometheus_io_port_1
          regex: '\d+'
        - action: keep
          sourceLabels:
            - __meta_kubernetes_service_port_name
            - __meta_kubernetes_service_annotation_prometheus_io_port_1
          regex: '(metrics;.*)|(.*;\d+)'
        - sourceLabels:
            - __meta_kubernetes_service_annotation_prometheus_io_scheme
          targetLabel: __scheme__
          regex: '(https?)'
        - sourceLabels:
            - __meta_kubernetes_service_annotation_prometheus_io_path
          targetLabel: __metrics_path__
          regex: '(.+)'
        - sourceLabels:
            - __address__
            - __meta_kubernetes_service_annotation_prometheus_io_port_1
          targetLabel: __address__
          regex: '([^:]+)(?::\d+)?;(\d+)'
          replacement: $1:$2
        - action: labelmap
          regex: '__meta_kubernetes_service_label_(.+)'
        - sourceLabels:
            - __meta_kubernetes_namespace
          targetLabel: kubernetes_namespace
        - sourceLabels:
            - __meta_kubernetes_service_name
          targetLabel: kubernetes_name
        - action: labelmap
          replacement: __param_$1
          regex: '__meta_kubernetes_service_annotation_prometheus_io_scrape_param_(.+)'
        - action: replace
          targetLabel: region
          replacement: qa-de-1
        - action: replace
          targetLabel: cluster_type
          replacement: controlplane
        - action: replace
          targetLabel: cluster
          replacement: qa-de-1
---
# Source: prometheus-vmware/charts/prometheus-server/templates/servicemonitors/prometheus.yaml
# This ServiceMonitor is used for monitoring the Prometheus itself and - if enabled - its Thanos components deployed alongside.
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor

metadata:
  name: prometheus-vmware
  labels:
    prometheus: vmware

spec:
  jobLabel: vmware

  selector:
    matchLabels:
      prometheus: vmware

  endpoints:
    - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
      interval: 30s
      scrapeTimeout: 25s
      port: http
      scheme: http
      relabelings:
        - action: replace
          targetLabel: prometheus
          replacement: vmware
        - action: labelmap
          regex: '__meta_kubernetes_service_label_(.+)'
        - sourceLabels:
            - __meta_kubernetes_namespace
          targetLabel: kubernetes_namespace
        - sourceLabels:
            - __meta_kubernetes_service_name
          targetLabel: kubernetes_name
        - action: replace
          targetLabel: region
          replacement: qa-de-1
        - action: replace
          targetLabel: cluster_type
          replacement: controlplane
        - action: replace
          targetLabel: cluster
          replacement: qa-de-1
---
# Source: prometheus-vmware/charts/prometheus-server/templates/vpa.yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: prometheus-vmware
  namespace: default
spec:
  targetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: prometheus-vmware
  updatePolicy:
    updateMode: "Off"
  resourcePolicy:
    containerPolicies:
      - containerName: '*'
        controlledResources:
          - cpu
          - memory
